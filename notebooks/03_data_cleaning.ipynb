{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.0 Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully loaded combined data from: ../data/processed/ecommerce_merged_initial.csv\n",
      "Starting Rows: 118434\n"
     ]
    }
   ],
   "source": [
    "FILE_PATH = '../data/processed/ecommerce_merged_initial.csv'\n",
    "\n",
    "# Load the single combined DataFrame directly\n",
    "df_combined = pd.read_csv(FILE_PATH) \n",
    "\n",
    "df_clean = df_combined.copy()\n",
    "\n",
    "print(f\"Successfully loaded combined data from: {FILE_PATH}\")\n",
    "print(f\"Starting Rows: {len(df_combined)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Standardize Formats (Date Conversion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Date Conversion Validation ---\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 113387 entries, 0 to 118433\n",
      "Data columns (total 6 columns):\n",
      " #   Column                         Non-Null Count   Dtype         \n",
      "---  ------                         --------------   -----         \n",
      " 0   order_purchase_timestamp       113387 non-null  datetime64[ns]\n",
      " 1   order_approved_at              113373 non-null  datetime64[ns]\n",
      " 2   order_delivered_carrier_date   113385 non-null  datetime64[ns]\n",
      " 3   order_delivered_customer_date  113379 non-null  datetime64[ns]\n",
      " 4   order_estimated_delivery_date  113387 non-null  datetime64[ns]\n",
      " 5   shipping_limit_date            113387 non-null  datetime64[ns]\n",
      "dtypes: datetime64[ns](6)\n",
      "memory usage: 6.1 MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "\n",
    "date_cols = [\n",
    "  'order_purchase_timestamp', \n",
    "    'order_approved_at', \n",
    "    'order_delivered_carrier_date', \n",
    "    'order_delivered_customer_date',\n",
    "    'order_estimated_delivery_date',\n",
    "    'shipping_limit_date'\n",
    " ]\n",
    "\n",
    "for col in date_cols:\n",
    "    df_clean[col] = pd.to_datetime(df_clean[col], errors='coerce')\n",
    "\n",
    "# Validation Check\n",
    "print(\"\\n--- Date Conversion Validation ---\")\n",
    "print(df_clean[date_cols].info())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Successfully converted all date colums to the correct date type"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Handle Missing Values: Filter Unsuccessful Orders (Most Critical)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Order Status Filter Validation ---\n",
      "Rows Removed (Incomplete Orders): 0\n",
      "Remaining Rows (Delivered): 113387\n",
      "New Order Statuses:\n",
      "order_status\n",
      "delivered    113387\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "original_count = len(df_clean)\n",
    "\n",
    "df_clean = df_clean[df_clean['order_status'] == 'delivered'].copy()\n",
    "\n",
    "removed_rows = original_count - len(df_clean)\n",
    "print(f\"\\n--- Order Status Filter Validation ---\")\n",
    "print(f\"Rows Removed (Incomplete Orders): {removed_rows}\")\n",
    "print(f\"Remaining Rows (Delivered): {len(df_clean)}\")\n",
    "print(f\"New Order Statuses:\\n{df_clean['order_status'].value_counts()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Critical Null Drop Validation ---\n",
      "Rows removed (Missing Price/Category): 0\n",
      "Remaining Rows: 113387\n",
      "Missing Categories: 0\n"
     ]
    }
   ],
   "source": [
    "original_count = len(df_clean)\n",
    "\n",
    "df_clean.dropna(subset=[\n",
    "    'price',\n",
    "    'freight_value',\n",
    "    'seller_id',\n",
    "    'product_category_name_english'\n",
    "], inplace=True)\n",
    "\n",
    "removed_rows = original_count - len(df_clean)\n",
    "print(f\"\\n--- Critical Null Drop Validation ---\")\n",
    "print(f\"Rows removed (Missing Price/Category): {removed_rows}\")\n",
    "print(f\"Remaining Rows: {len(df_clean)}\")\n",
    "print(f\"Missing Categories: {df_clean['product_category_name_english'].isnull().sum()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Successfully removed missing rows form \"price\", \"freight_value\", \"seller_id\", \"product_category_name_english\" for accuarte calculation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Consolidate Payment Duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Duplicate Aggregation Validation ---\n",
      "Rows Removed (Consolidated Payments): 4749\n",
      "Final Cleaned Rows: 108638\n",
      "Duplicates: 0\n"
     ]
    }
   ],
   "source": [
    "original_count = len(df_clean)\n",
    "\n",
    "df_final = df_clean.groupby(['order_id', 'order_item_id'], as_index=False).agg(\n",
    "    \n",
    "    # Financial Aggregation\n",
    "    total_paid=('payment_value', 'sum'),       \n",
    "    price=('price', 'mean'),                   \n",
    "    freight_value=('freight_value', 'mean'),   \n",
    "    \n",
    "    # Identifying/Categorical Columns\n",
    "    customer_unique_id=('customer_unique_id', 'first'),\n",
    "    product_category_name_english=('product_category_name_english', 'first'),\n",
    "    customer_state=('customer_state', 'first'),\n",
    "    seller_id=('seller_id', 'first'),          \n",
    "    \n",
    "    # Date/Time Columns\n",
    "    order_purchase_timestamp=('order_purchase_timestamp', 'first'),\n",
    "    order_approved_at=('order_approved_at', 'first'),              # Added for fulfillment metrics\n",
    "    order_delivered_carrier_date=('order_delivered_carrier_date', 'first'), # Added for fulfillment metrics\n",
    "    order_delivered_customer_date=('order_delivered_customer_date', 'first'),\n",
    "    order_estimated_delivery_date=('order_estimated_delivery_date', 'first'),\n",
    "    shipping_limit_date=('shipping_limit_date', 'first')           # Added for SLA metrics\n",
    ")\n",
    "\n",
    "removed_rows = original_count - len(df_final)\n",
    "print(f\"\\n--- Duplicate Aggregation Validation ---\")\n",
    "print(f\"Rows Removed (Consolidated Payments): {removed_rows}\")\n",
    "print(f\"Final Cleaned Rows: {len(df_final)}\")\n",
    "print(f\"Duplicates: {df_final.duplicated().sum()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Aggregate rows based on the unique transaction key (`order_id` + `order_item_id`) to fix the 5,009 payment duplicates**.\n",
    "\n",
    "* **SUM:** `payment_value` to create `total_paid` (since values were split).\n",
    "* **FIRST/MEAN:** Used for all identifying columns (`price`, `customer_id`, `date`) since their values were identical across duplicated rows."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### New Useful Columns (Feature Engineering Prep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Revenue & Time Feature Validation ---\n",
      "Sample Revenue Check:\n",
      "    price  freight_value  revenue\n",
      "0   58.90          13.29    72.19\n",
      "1  239.90          19.93   259.83\n",
      "2  199.00          17.87   216.87\n",
      "3   12.99          12.79    25.78\n",
      "4  199.90          18.14   218.04\n",
      "Sample Time Feature Check:\n",
      "  order_purchase_timestamp order_year_month\n",
      "0      2017-09-13 08:59:02          2017-09\n",
      "1      2017-04-26 10:53:06          2017-04\n",
      "2      2018-01-14 14:33:31          2018-01\n",
      "3      2018-08-08 10:00:35          2018-08\n",
      "4      2017-02-04 13:57:51          2017-02\n"
     ]
    }
   ],
   "source": [
    "#Transaction Revenue\n",
    "df_final['revenue'] = df_final['price'] + df_final['freight_value']\n",
    "\n",
    "#Time Features\n",
    "df_final['order_year_month'] = df_final['order_purchase_timestamp'].dt.to_period('M')\n",
    "df_final['order_month'] = df_final['order_purchase_timestamp'].dt.month\n",
    "df_final['order_year'] = df_final['order_purchase_timestamp'].dt.year\n",
    "\n",
    "print(\"\\n--- Revenue & Time Feature Validation ---\")\n",
    "print(f\"Sample Revenue Check:\\n{df_final[['price', 'freight_value', 'revenue']].head()}\")\n",
    "print(f\"Sample Time Feature Check:\\n{df_final[['order_purchase_timestamp', 'order_year_month']].head()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The new columns create for future calculations of LTV "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saved the Cleaned DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "SUCCESS: Cleaned data saved to '../data/processed/ecommerce_clean.csv'\n"
     ]
    }
   ],
   "source": [
    "df_final.to_csv('../data/processed/ecommerce_clean.csv', index=False)\n",
    "print(\"\\nSUCCESS: Cleaned data saved to '../data/processed/ecommerce_clean.csv'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['order_id', 'order_item_id', 'total_paid', 'price', 'freight_value',\n",
      "       'customer_unique_id', 'product_category_name_english', 'customer_state',\n",
      "       'seller_id', 'order_purchase_timestamp', 'order_approved_at',\n",
      "       'order_delivered_carrier_date', 'order_delivered_customer_date',\n",
      "       'order_estimated_delivery_date', 'shipping_limit_date', 'revenue',\n",
      "       'order_year_month', 'order_month', 'order_year'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(df_final.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Final columns in the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ecommerce-analysis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
